"""
ç®€å•æµ‹è¯•è„šæœ¬ - éªŒè¯åŸºæœ¬åŠŸèƒ½
"""

import torch
import traceback

def test_components():
    """æµ‹è¯•åŸºç¡€ç»„ä»¶"""
    print("=== æµ‹è¯•åŸºç¡€ç»„ä»¶ ===")
    
    try:
        from facial_reaction_model.components import PositionalEncoding
        
        # æµ‹è¯•PositionalEncoding
        pe = PositionalEncoding(d_model=256, dropout=0.1)
        test_input = torch.randn(2, 16, 256)  # (batch, seq, features)
        output = pe(test_input)
        print(f"âœ… PositionalEncodingæˆåŠŸ - è¾“å…¥: {test_input.shape}, è¾“å‡º: {output.shape}")
        
    except Exception as e:
        print(f"âŒ åŸºç¡€ç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True


def test_vae_simple():
    """ç®€å•VAEæµ‹è¯•"""
    print("\n=== æµ‹è¯•VAEæ¨¡å— ===")
    
    try:
        from facial_reaction_model.vae import FacialVAE
        
        # åˆ›å»ºVAE
        vae = FacialVAE(feature_dim=256, latent_dim=256)
        print("âœ… VAEåˆ›å»ºæˆåŠŸ")
        
        # ç®€å•å‰å‘ä¼ æ’­æµ‹è¯•
        test_input = torch.randn(2, 8, 256)  # æ›´å°çš„è¾“å…¥
        motion_sample, distribution = vae(test_input)
        
        print(f"âœ… VAEå‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        print(f"Motion sampleå½¢çŠ¶: {motion_sample.shape}")
        print(f"Distribution meanå½¢çŠ¶: {distribution.mean.shape}")
        
    except Exception as e:
        print(f"âŒ VAEæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True


def test_encoder():
    """æµ‹è¯•ç¼–ç å™¨"""
    print("\n=== æµ‹è¯•ç¼–ç å™¨ ===")
    
    try:
        from facial_reaction_model.encoder import SpeakerEncoder
        
        # åˆ›å»ºç¼–ç å™¨
        encoder = SpeakerEncoder(feature_dim=256, audio_dim=384, device='cpu')
        print("âœ… SpeakerEncoderåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®
        batch_size, seq_len = 2, 16
        speaker_data = {
            'landmarks': torch.randn(batch_size, seq_len, 136),
            'au': torch.randn(batch_size, seq_len, 18),
            'pose': torch.randn(batch_size, seq_len, 4),
            'gaze': torch.randn(batch_size, seq_len, 2),
            'audio': torch.randn(batch_size, seq_len, 384)
        }
        
        speaker_motion, speaker_audio, speaker_vector = encoder(speaker_data)
        
        print(f"âœ… SpeakerEncoderå‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"Speaker motionå½¢çŠ¶: {speaker_motion.shape}")
        print(f"Speaker audioå½¢çŠ¶: {speaker_audio.shape}")
        print(f"Speaker vectorå½¢çŠ¶: {speaker_vector.shape}")
        
    except Exception as e:
        print(f"âŒ ç¼–ç å™¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True


def test_decoder():
    """æµ‹è¯•è§£ç å™¨"""
    print("\n=== æµ‹è¯•è§£ç å™¨ ===")
    
    try:
        from facial_reaction_model.decoder import ListenerReactionDecoder
        
        # åˆ›å»ºè§£ç å™¨
        decoder = ListenerReactionDecoder(feature_dim=256, window_size=8, device='cpu')
        print("âœ… ListenerReactionDecoderåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®
        batch_size, window_size = 2, 8
        motion_sample = torch.randn(batch_size, 1, 256)
        speaker_motion = torch.randn(batch_size, window_size, 256)
        speaker_audio = torch.randn(batch_size, window_size * 2, 256)
        
        predictions = decoder(motion_sample, speaker_motion, speaker_audio)
        
        print(f"âœ… ListenerReactionDecoderå‰å‘ä¼ æ’­æˆåŠŸ")
        print("é¢„æµ‹ç»“æœå½¢çŠ¶:")
        for key, value in predictions.items():
            print(f"  {key}: {value.shape}")
        
    except Exception as e:
        print(f"âŒ è§£ç å™¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True


def test_minimal_model():
    """æµ‹è¯•æœ€å°æ¨¡å‹"""
    print("\n=== æµ‹è¯•æœ€å°æ¨¡å‹ ===")
    
    try:
        from facial_reaction_model.model import FacialReactionModel
        
        # åˆ›å»ºè¾ƒå°çš„æ¨¡å‹
        model = FacialReactionModel(
            feature_dim=128,  # å‡å°ç‰¹å¾ç»´åº¦
            audio_dim=384,
            window_size=8,    # å‡å°çª—å£å¤§å°
            device='cpu'
        )
        print("âœ… FacialReactionModelåˆ›å»ºæˆåŠŸ")
        
        # ä½¿ç”¨å¾ˆå°çš„æµ‹è¯•æ•°æ®
        batch_size, seq_len = 1, 16  # å•batchï¼ŒçŸ­åºåˆ—
        speaker_data = {
            'landmarks': torch.randn(batch_size, seq_len, 136),
            'au': torch.randn(batch_size, seq_len, 18),
            'pose': torch.randn(batch_size, seq_len, 4),
            'gaze': torch.randn(batch_size, seq_len, 2),
            'audio': torch.randn(batch_size, seq_len, 384)
        }
        
        print("å¼€å§‹å‰å‘ä¼ æ’­...")
        predictions, distributions, _ = model(speaker_data, speaker_out=False)
        
        print(f"âœ… æœ€å°æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ")
        print("é¢„æµ‹ç»“æœå½¢çŠ¶:")
        for key, value in predictions.items():
            print(f"  {key}: {value.shape}")
        print(f"åˆ†å¸ƒæ•°é‡: {len(distributions)}")
        
    except Exception as e:
        print(f"âŒ æœ€å°æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç®€å•æµ‹è¯•...")
    
    tests = [
        ("åŸºç¡€ç»„ä»¶", test_components),
        ("VAEæ¨¡å—", test_vae_simple),
        ("ç¼–ç å™¨", test_encoder),
        ("è§£ç å™¨", test_decoder),
        ("æœ€å°æ¨¡å‹", test_minimal_model)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯• {test_name}")
        print('='*50)
        
        if test_func():
            passed += 1
            print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
        else:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
    
    print(f"\n{'='*50}")
    print(f"æµ‹è¯•æ€»ç»“: {passed}/{total} é€šè¿‡")
    print('='*50)
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âŒ ä»æœ‰å¤±è´¥çš„æµ‹è¯•")
        return False


if __name__ == "__main__":
    # è®¾ç½®torchä¸ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œé¿å…ä¸€äº›æ½œåœ¨é—®é¢˜
    torch.set_num_threads(1)
    main()